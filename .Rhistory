install.packages("Rcmdr")
library(dplyr); library(ggplot2); library(lattice);
library(caret); library(gbm); library(survival);
library(randomForest); library(MASS); library(mice);
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL, destfile = "training.csv", method = "curl")
training <- read.csv("training.csv")
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL, destfile = "testing.csv", method = "curl")
testing <- read.csv("testing.csv")
set.seed(12345)
train <- training[which(colSums(is.na(training)) == 0)]
head(rain)
head(train)
modelGBM <- train(classe~.,method= "gbm", data = train)
names(train)
head(train)
head(train[,1])
head(train[,c(5, dim(training)[1])])
head(train[,c(5, dim(train)[1])])
dim(train)
dim(train)[2]
head(train[,c(5, dim(train)[2])])
head(train[,c(5: dim(train)[2])])
head(train[,c(7: dim(train)[2])],1)
head(train[,c(8: dim(train)[2])],1)
head(train[,c(8: dim(train)[2])],1)
train <- training[which(colSums(is.na(training)) == 0)]
train <- train[,c(8: dim(train)[2])]
modelRF <- train(classe~.,method = "rf", data = train)
modelRF <- randomForest(classe~., data = train)
preProcPCA <- preProcess(train, method = "pca", thresh = 0.99)
trainPCA <- predict(preProcPCA, train)
trainPCA <- data.frame(classe = trainPCA$classe, trainPCA[grep("^PC",names(trainPCA))])
modelRF <- randomForest(classe~., data = trainPCA)
confusionMatrix(trainPCA$classe, predict(modelRF, trainPCA))
test <- testing[which(colSums(is.na(training)) == 0)]
testPCA <- predict(preProcPCA, test)
testPCA <- data.frame(testPCA[grep("^PC",names(testPCA))])
predict(modelRF, testPCA)
setwd("/Users/sophieyang/datasciencecoursera/Prediction_Assignment_Writeup
")
setwd("/Users/sophieyang/datasciencecoursera/Prediction_Assignment_Writeup")
library(dplyr); library(ggplot2); library(lattice);
library(caret); library(gbm); library(survival);
library(randomForest); library(MASS); library(mice);
library(plyr);library(reshape2);
library(rattle)
training <- read.csv("training.csv")
testing <- read.csv("testing.csv")
set.seed(12345)
train <- training[which(colSums(is.na(training)) == 0)]
train <- train[,c(8: dim(train)[2])]
# 2. We still have too many variables at hand, so we use PCA to narrow it down
preProcPCA <- preProcess(train, method = "pca", thresh = 0.99)
trainPCA <- predict(preProcPCA, train)
trainPCA <- data.frame(classe = trainPCA$classe, trainPCA[grep("^PC",names(trainPCA))])
# 3. Next we train our model using LDA, since we have multiple classes
modelRF <- randomForest(classe~., data = trainPCA)
fancyRpartPlot(modelRF$finalModel)
fancyRpartPlot(modelRF)
fancyRpartPlot(modelRF$forest)
summary(modelRF)
fancyRpartPlot(modelRF$classes)
fancyRpartPlot(modelRF)
fancyRpartPlot
?fancyRpartPlot
fancyRpartPlot(modelRF$call)
fancyRpartPlot(modelRF$type)
fancyRpartPlot(modelRF$votes)
fancyRpartPlot(modelRF$terms)
fancyRpartPlot(modelRF$predicted)
plot(modelRF)
plot(modelRF$predicted)
plot(modelRF$predicted~modelRF$classes)
getTree(modelRF, 1, labelVar=TRUE)
tree <- getTree(modelRF, 1, labelVar=TRUE)
plot(tree)
fancyRpartPlot(tree)
library(reprtree)
install.packages("reprtree")
library(reprtree)
data(mtcars)
plot(randomForest(mpg ~ ., mtcars, keep.forest=FALSE, ntree=100), log="y")
library(party)
install.packages("party")
library(party)
plot(modelRF, type="simple")
library("party")
plot(modelRF, type="simple")
plot(modelRF)
plot(tree)
plot(modelRF, type = "l")
tree
head(tree)
featurePlot(x = trainPCA[,3:dim(trainPCA)[2]], y = trainPCA[,2], "scatter")
)))
plot(PC1~PC2,trainPCA)
)
